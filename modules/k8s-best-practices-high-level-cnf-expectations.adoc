[id="k8s-best-practices-high-level-cnf-expectations"]
= High-level workload expectations

* Workloads shall be built to be cloud-native

* Containers MUST NOT run as root (uid=0). See test case link:https://github.com/test-network-function/cnf-certification-test/blob/main/CATALOG.md#access-control-security-context-non-root-user-id-check[access-control-security-context-non-root-user-id-check]

**Impacts and Risks of Non-Compliance:** Running containers as root increases the blast radius of security vulnerabilities and can lead to full host compromise if containers are breached.

* Containers MUST run with the minimal set of permissions required. Avoid Privileged Pods. See test case link:https://github.com/test-network-function/cnf-certification-test/blob/main/CATALOG.md#access-control-security-context-privilege-escalation[access-control-security-context-privilege-escalation]

**Impacts and Risks of Non-Compliance:** Allowing privilege escalation can lead to containers gaining root access, compromising the security boundary between containers and hosts.

* Use the main CNI for all traffic - MULTUS/SRIOV/MacVLAN are for corner cases only (extreme throughput requirements, protocols that are unable to be load balanced)

* Workloads should employ N+k redundancy models

* Workloads MUST define their pod affinity/anti-affinity rules. See test cases link:https://github.com/test-network-function/cnf-certification-test/blob/main/CATALOG.md#lifecycle-affinity-required-pods[lifecycle-affinity-required-pods], link:https://github.com/test-network-function/cnf-certification-test/blob/main/CATALOG.md#lifecycle-pod-high-availability[lifecycle-pod-high-availability]

**Impacts and Risks of Non-Compliance:** Missing affinity rules can cause incorrect pod placement, leading to performance issues and failure to meet co-location requirements.

* All secondary network interfaces employed by workloads with the use of MULTUS MUST support Dual-Stack IPv4/IPv6.

For platform using IPv4 addressing for CNI interfaces, and a NAT46/64 implementation in Services Proxy/Load Balancer for Ingress & Egress traffic. Workloads shall support this requirement.

* Instantiation of a workload (via Helm chart or Operators or otherwise) shall result in a fully-functional workload ready to serve traffic, without requiring any post-instantiation configuration of system parameters

* Workloads shall implement service resilience at the application layer and not rely on individual compute availability/stability

* Workloads shall decouple application configuration from Pods, to allow dynamic configuration updates

* Workloads shall support elasticity with dynamic scale up/down using kubernetes-native constructs such as ReplicaSets, etc. See test cases link:https://github.com/test-network-function/cnf-certification-test/blob/main/CATALOG.md#lifecycle-crd-scaling[lifecycle-crd-scaling], link:https://github.com/test-network-function/cnf-certification-test/blob/main/CATALOG.md#lifecycle-statefulset-scaling[lifecycle-statefulset-scaling], link:https://github.com/test-network-function/cnf-certification-test/blob/main/CATALOG.md#lifecycle-deployment-scaling[lifecycle-deployment-scaling]

**Impacts and Risks of Non-Compliance:** CRD scaling failures can prevent operator-managed applications from scaling properly, limiting application availability and performance.

* Workloads shall support canary upgrades

* Workloads shall self-recover from common failures like pod failure, host failure, and network failure. Kubernetes native mechanisms such as health-checks (Liveness, Readiness and Startup Probes) shall be employed at a minimum. See test cases link:https://github.com/test-network-function/cnf-certification-test/blob/main/CATALOG.md#lifecycle-liveness-probe[lifecycle-liveness-probe], link:https://github.com/test-network-function/cnf-certification-test/blob/main/CATALOG.md#lifecycle-readiness-probe[lifecycle-readiness-probe], link:https://github.com/test-network-function/cnf-certification-test/blob/main/CATALOG.md#lifecycle-startup-probe[lifecycle-startup-probe]

**Impacts and Risks of Non-Compliance:** Missing liveness probes prevent Kubernetes from detecting and recovering from application deadlocks and hangs.

.Workload requirement
[IMPORTANT]
====
Containers must not run as root

See test case link:https://github.com/test-network-function/cnf-certification-test/blob/main/CATALOG.md#access-control-security-context-non-root-user-id-check[access-control-security-context-non-root-user-id-check]

**Impacts and Risks of Non-Compliance:** Running containers as root increases the blast radius of security vulnerabilities and can lead to full host compromise if containers are breached.
====

.Workload requirement
[IMPORTANT]
====
All secondary interfaces (MULTUS) must support dual stack

See test cases link:https://github.com/test-network-function/cnf-certification-test/blob/main/CATALOG.md#networking-icmpv4-connectivity-multus[networking-icmpv4-connectivity-multus], link:https://github.com/test-network-function/cnf-certification-test/blob/main/CATALOG.md#networking-icmpv6-connectivity-multus[networking-icmpv6-connectivity-multus]

**Impacts and Risks of Non-Compliance:** Multus network connectivity issues can isolate workloads from secondary networks, breaking multi-network applications and reducing network redundancy.
====

.Workload requirement
[IMPORTANT]
====
Workloads shall not use node selectors nor taints/tolerations to assign pod location

See test cases link:https://github.com/test-network-function/cnf-certification-test/blob/main/CATALOG.md#lifecycle-pod-scheduling[lifecycle-pod-scheduling], link:https://github.com/test-network-function/cnf-certification-test/blob/main/CATALOG.md#platform-alteration-tainted-node-kernel[platform-alteration-tainted-node-kernel]

**Impacts and Risks of Non-Compliance:** Node selectors can create scheduling constraints that reduce cluster flexibility and cause deployment failures when nodes are unavailable.
====

